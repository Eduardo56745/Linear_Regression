# ğŸ” OfuscaciÃ³n de Datos en RegresiÃ³n Lineal

Este proyecto demuestra cÃ³mo es posible proteger la **privacidad de los datos** sin sacrificar la precisiÃ³n de un modelo predictivo. A travÃ©s de una **transformaciÃ³n lineal mediante una matriz invertible**, se implementa una tÃ©cnica de ofuscaciÃ³n que **mantiene intactas las predicciones y mÃ©tricas de rendimiento** de una regresiÃ³n lineal.

---

## ğŸ¯ Objetivos del Proyecto

- âœ… Entrenar un modelo de **regresiÃ³n lineal** sobre un conjunto de datos reales.
- ğŸ” Aplicar una **transformaciÃ³n invertible** a los datos de entrenamiento para simular ofuscaciÃ³n.
- ğŸ“Š Evaluar el impacto de la transformaciÃ³n en los valores predichos y las mÃ©tricas del modelo.
- ğŸ§® Verificar matemÃ¡ticamente que los resultados permanecen constantes.

---

## ğŸ› ï¸ TÃ©cnicas y Herramientas

- Python ğŸ  
- NumPy & Pandas ğŸ“Š  
- Scikit-learn ğŸ¤–  
- Ãlgebra lineal aplicada ğŸ”¢  
- VisualizaciÃ³n con Matplotlib

---

## ğŸ“ˆ Resultados Clave

- ğŸ“Œ Las predicciones del modelo se **mantienen idÃ©nticas** tras la transformaciÃ³n.
- ğŸ“‰ Las mÃ©tricas de rendimiento (RMSE y RÂ²) **no presentan variaciÃ³n alguna**.
- ğŸ”’ Se confirma que la **ofuscaciÃ³n preserva la utilidad** del modelo mientras **protege la informaciÃ³n sensible**.
  
---

## ğŸ§  ConclusiÃ³n

Este enfoque demuestra que la **seguridad y la privacidad de los datos pueden coexistir** con modelos precisos en machine learning. La ofuscaciÃ³n mediante transformaciÃ³n lineal es una tÃ©cnica eficiente que **no compromete la calidad del modelo**, lo cual es especialmente Ãºtil en entornos donde la confidencialidad es crÃ­tica.

---

ğŸ“« Â¿Te interesa explorar mÃ¡s tÃ©cnicas de protecciÃ³n de datos en ciencia de datos? Â¡Estoy abierto a nuevos desafÃ­os y colaboraciones!

