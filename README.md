# 🔏 Ofuscación de Datos en Regresión Lineal

Este proyecto demuestra cómo es posible proteger la **privacidad de los datos** sin sacrificar la precisión de un modelo predictivo. A través de una **transformación lineal mediante una matriz invertible**, se implementa una técnica de ofuscación que **mantiene intactas las predicciones y métricas de rendimiento** de una regresión lineal.

---

## 🎯 Objetivos del Proyecto

- ✅ Entrenar un modelo de **regresión lineal** sobre un conjunto de datos reales.
- 🔁 Aplicar una **transformación invertible** a los datos de entrenamiento para simular ofuscación.
- 📊 Evaluar el impacto de la transformación en los valores predichos y las métricas del modelo.
- 🧮 Verificar matemáticamente que los resultados permanecen constantes.

---

## 🛠️ Técnicas y Herramientas

- Python 🐍  
- NumPy & Pandas 📊  
- Scikit-learn 🤖  
- Álgebra lineal aplicada 🔢  
- Visualización con Matplotlib

---

## 📈 Resultados Clave

- 📌 Las predicciones del modelo se **mantienen idénticas** tras la transformación.
- 📉 Las métricas de rendimiento (RMSE y R²) **no presentan variación alguna**.
- 🔒 Se confirma que la **ofuscación preserva la utilidad** del modelo mientras **protege la información sensible**.
  
---

## 🧠 Conclusión

Este enfoque demuestra que la **seguridad y la privacidad de los datos pueden coexistir** con modelos precisos en machine learning. La ofuscación mediante transformación lineal es una técnica eficiente que **no compromete la calidad del modelo**, lo cual es especialmente útil en entornos donde la confidencialidad es crítica.

---

📫 ¿Te interesa explorar más técnicas de protección de datos en ciencia de datos? ¡Estoy abierto a nuevos desafíos y colaboraciones!

